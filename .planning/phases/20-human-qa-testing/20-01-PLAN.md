---
phase: 20-human-qa-testing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - QA/TESTING-GUIDE.md
  - QA/FULL-TEST-CHECKLIST.md
  - QA/SMOKE-TEST-CHECKLIST.md
autonomous: true

must_haves:
  truths:
    - "Human tester can find and read QA testing procedures"
    - "Human tester can execute full test checklist and record pass/fail results"
    - "Human tester can execute smoke test checklist in under 10 minutes"
    - "Failure documentation requirements are clear"
    - "Release gate criteria are unambiguous"
  artifacts:
    - path: "QA/TESTING-GUIDE.md"
      provides: "When to test, how to document failures, release gate criteria"
      contains: "Release Gate Criteria"
    - path: "QA/FULL-TEST-CHECKLIST.md"
      provides: "Comprehensive test coverage for all LSP features"
      contains: "Feature | Steps | Expected | Pass/Fail"
    - path: "QA/SMOKE-TEST-CHECKLIST.md"
      provides: "Quick sanity test for rapid verification"
      contains: "Feature | Steps | Expected | Pass/Fail"
  key_links:
    - from: "QA/TESTING-GUIDE.md"
      to: "QA/FULL-TEST-CHECKLIST.md"
      via: "Reference in when-to-test section"
      pattern: "FULL-TEST-CHECKLIST.md"
    - from: "QA/TESTING-GUIDE.md"
      to: "QA/SMOKE-TEST-CHECKLIST.md"
      via: "Reference in when-to-test section"
      pattern: "SMOKE-TEST-CHECKLIST.md"
---

<objective>
Create human QA testing documentation with recurring testing checklists for the BBj Language Server.

Purpose: Enable human testers to perform repeatable pre-release verification of all language server features in both VS Code and IntelliJ, with clear pass/fail criteria and failure documentation procedures.

Output: Three documentation files in a new QA/ directory -- a testing guide explaining procedures, a comprehensive full test checklist, and a quick smoke test checklist.
</objective>

<execution_context>
@/Users/beff/.claude/get-shit-done/workflows/execute-plan.md
@/Users/beff/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/20-human-qa-testing/20-CONTEXT.md
@.planning/phases/20-human-qa-testing/20-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create QA directory and TESTING-GUIDE.md</name>
  <files>QA/TESTING-GUIDE.md</files>
  <action>
Create the QA/ directory at project root and write TESTING-GUIDE.md with these sections:

1. **Overview** - Purpose of QA testing documentation
2. **When to Test** section specifying:
   - Smoke Test: Before every release candidate, after significant changes
   - Full Test: Before each production release
   - Ad-hoc: When investigating reported bugs
3. **How to Document Test Runs** section with:
   - Copy template to QA/test-runs/ with date prefix
   - Mark Pass/Fail in checklist
   - Rename with -PASS or -FAIL suffix
   - Example: `QA/test-runs/2026-02-04-full-test-PASS.md`
4. **Failure Evidence Requirements** section:
   - Required: Screenshot or log excerpt for failures
   - Append evidence section to test run file
   - Include: Test name, date, tester, failure description, steps to reproduce, expected vs actual, link to GitHub issue for screenshots
5. **Release Gate Criteria** section:
   - PASS: All items in FULL-TEST-CHECKLIST.md show PASS
   - BLOCK: Any item shows FAIL (no exceptions)
   - Evidence: Failures require screenshots/logs, passes do not
6. **Maintaining Checklists** section:
   - Checklists are living documents
   - Add tests for new features
   - Remove obsolete tests
   - Changes via pull request
  </action>
  <verify>
    - `test -d QA` returns 0 (directory exists)
    - `test -f QA/TESTING-GUIDE.md` returns 0 (file exists)
    - `grep -q "Release Gate Criteria" QA/TESTING-GUIDE.md` returns 0
    - `grep -q "FULL-TEST-CHECKLIST.md" QA/TESTING-GUIDE.md` returns 0
    - `grep -q "SMOKE-TEST-CHECKLIST.md" QA/TESTING-GUIDE.md` returns 0
  </verify>
  <done>TESTING-GUIDE.md exists with all required sections: overview, when to test, how to document, failure evidence, release gates, maintaining checklists</done>
</task>

<task type="auto">
  <name>Task 2: Create FULL-TEST-CHECKLIST.md</name>
  <files>QA/FULL-TEST-CHECKLIST.md</files>
  <action>
Create comprehensive test checklist covering all features. Use Markdown tables with columns: Feature | Steps | Expected | Pass/Fail

Structure the file with these sections:

**Header:**
- Title, purpose, estimated time (30-45 minutes)
- Instructions: Copy to test-runs/ before executing

**VS Code - LSP Features** (9 tests):
| Feature | Steps | Expected | Pass/Fail |
1. Syntax Highlighting - Open examples/bbj-classes.bbj, verify keywords colored distinctly
2. Diagnostics - Create file, type `MODE "INVALID"`, save, verify red squiggle
3. Code Completion (BBj) - Type `PR` + Ctrl+Space, verify PRINT appears
4. Code Completion (Java) - Type `use java.util.Hash` + Ctrl+Space, verify HashMap appears
5. Hover Information - Hover over variable usage, verify tooltip with type info
6. Signature Help - Type `STR(`, verify parameter popup
7. Go-to-Definition - Right-click method call, select Go to Definition, verify navigation
8. Document Symbols - Open Outline (Ctrl+Shift+O), verify class/method/field hierarchy
9. Semantic Tokens - Verify variables colored differently from keywords

**IntelliJ IDEA - LSP Features** (mirror of VS Code section with IntelliJ-specific steps)

**VS Code - Run Commands** (3 tests):
1. Run Program - Right-click .bbj file, Run BBj > Run Program
2. Run with Debug - Right-click .bbj file, Run BBj > Run with Debug
3. Run as BUI/DWC (if applicable)

**IntelliJ IDEA - Run Commands** (3 tests):
1. Run Program - Right-click .bbj file, Run BBj > Run Program
2. Run with Debug - Right-click .bbj file, Run BBj > Run with Debug
3. Run as BUI/DWC (if applicable)

**Enterprise Manager Integration** (2-3 tests):
1. EM Connection - Verify EM settings accessible
2. EM Operations - Test any EM-specific features (note: add details based on actual EM integration points)

**Footer:**
- Test run result: [ ] PASS (all items pass) or [ ] FAIL (any item fails)
- Date and tester fields

Include inline code snippets in Steps column where helpful (e.g., exact code to type).
Use `<br>` for line breaks within table cells.
Use `[ ]` for empty Pass/Fail checkboxes.
  </action>
  <verify>
    - `test -f QA/FULL-TEST-CHECKLIST.md` returns 0
    - `grep -q "VS Code - LSP Features" QA/FULL-TEST-CHECKLIST.md` returns 0
    - `grep -q "IntelliJ IDEA" QA/FULL-TEST-CHECKLIST.md` returns 0
    - `grep -q "Syntax Highlighting" QA/FULL-TEST-CHECKLIST.md` returns 0
    - `grep -q "Code Completion" QA/FULL-TEST-CHECKLIST.md` returns 0
    - `grep -q "Run Program" QA/FULL-TEST-CHECKLIST.md` returns 0
    - `grep -c "| \[ \]" QA/FULL-TEST-CHECKLIST.md` shows 20+ tests
  </verify>
  <done>FULL-TEST-CHECKLIST.md exists with VS Code and IntelliJ sections, covering all 9 LSP features, Run commands, and EM integration, with empty Pass/Fail checkboxes</done>
</task>

<task type="auto">
  <name>Task 3: Create SMOKE-TEST-CHECKLIST.md</name>
  <files>QA/SMOKE-TEST-CHECKLIST.md</files>
  <action>
Create quick sanity test checklist with 6-8 critical path items. Use Markdown table with columns: # | Feature | Steps | Expected | Pass/Fail

Structure the file:

**Header:**
- Title, purpose (quick sanity check)
- Estimated time: 5-10 minutes
- When to use: After any build, before detailed testing
- Release gate: If ANY item fails, run full test checklist

**Smoke Test Table** (6-8 items):
| # | Feature | Steps | Expected | Pass/Fail |
| 1 | Extension Loads (VS Code) | Open VS Code, open any .bbj file | No error notifications, file opens | [ ] |
| 2 | Syntax Highlighting | Open examples/bbj-classes.bbj | Keywords are colored | [ ] |
| 3 | Code Completion (BBj) | Type `PR` + Ctrl+Space | Completion shows PRINT | [ ] |
| 4 | Code Completion (Java) | Type `Hash` + Ctrl+Space | Completion shows HashMap | [ ] |
| 5 | Diagnostics | Type `MODE "INVALID"`, save | Red squiggle appears | [ ] |
| 6 | IntelliJ Basic | Open IntelliJ, open .bbj file | Syntax highlighting works | [ ] |
| 7 | Run Program | Right-click .bbj, Run Program | Program executes | [ ] |

**Footer:**
- Result: [ ] PASS (all items pass) or [ ] FAIL (any item fails)
- If FAIL: Run FULL-TEST-CHECKLIST.md and document failures
- Date and tester fields

Keep steps brief - these are reminders for testers who know the product.
  </action>
  <verify>
    - `test -f QA/SMOKE-TEST-CHECKLIST.md` returns 0
    - `grep -q "Smoke Test" QA/SMOKE-TEST-CHECKLIST.md` returns 0
    - `grep -q "5-10 minutes" QA/SMOKE-TEST-CHECKLIST.md` returns 0
    - `grep -c "| \[ \]" QA/SMOKE-TEST-CHECKLIST.md` shows 6-10 tests
    - `grep -q "FULL-TEST-CHECKLIST.md" QA/SMOKE-TEST-CHECKLIST.md` returns 0
  </verify>
  <done>SMOKE-TEST-CHECKLIST.md exists with 6-8 critical path tests, under 10 minute execution time, with reference to full checklist on failure</done>
</task>

</tasks>

<verification>
All verification commands should pass:
```bash
# Directory structure
test -d QA && echo "QA directory exists"

# All files present
ls -la QA/*.md

# Testing guide contains required sections
grep -l "Release Gate Criteria" QA/TESTING-GUIDE.md
grep -l "Failure Evidence" QA/TESTING-GUIDE.md

# Full checklist covers both IDEs
grep -c "VS Code" QA/FULL-TEST-CHECKLIST.md
grep -c "IntelliJ" QA/FULL-TEST-CHECKLIST.md

# Smoke test is appropriately sized
wc -l QA/SMOKE-TEST-CHECKLIST.md  # Should be ~50-80 lines
```
</verification>

<success_criteria>
1. QA/ directory exists at project root
2. TESTING-GUIDE.md explains when to test, how to document failures, and release gate criteria
3. FULL-TEST-CHECKLIST.md covers all 9 LSP features for both VS Code and IntelliJ
4. FULL-TEST-CHECKLIST.md covers Run commands for both IDEs
5. FULL-TEST-CHECKLIST.md includes EM integration tests
6. SMOKE-TEST-CHECKLIST.md contains 6-8 quick sanity tests
7. All checklists use Markdown tables with Feature | Steps | Expected | Pass/Fail columns
8. All Pass/Fail columns show empty checkboxes `[ ]` (not pre-filled)
</success_criteria>

<output>
After completion, create `.planning/phases/20-human-qa-testing/20-01-SUMMARY.md`
</output>
